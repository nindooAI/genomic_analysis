{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Today the biomedical after doing the genetic mapping need to manually search the referencing of the\n",
    "report on thousands of Pubmed articles.\n",
    "What takes a lot of biomedical time and makes it impossible him to impact other lives through his work.\n",
    "\n",
    "# Challenge \n",
    "\n",
    "- How would you help the biomedical with an AI that understands the context of scientific papers and make recommendations from the biomedical question?\n",
    "- What is the best approach / model for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IN OTHER WORDS:** The goal of this project/research is to find out how can I use AI to seek the answer of Biodical query/question based on the content of PubMed article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undestanding the context (basic search)\n",
    "\n",
    "- [Biomedical](https://www.guiadacarreira.com.br/salarios/quanto-ganha-um-biomedico/): research, identifies and classifies microorganisms that cause diseases and develops or improves medicines and vaccines to combat and prevent these diseases.\n",
    "\n",
    "\n",
    "- [Genetic Mapping](https://www.genome.gov/10000715/genetic-mapping-fact-sheet/): \"Among the main goals of the Human Genome Project (HGP) was to develop new, better and cheaper tools to identify new genes and to understand their function. One of these tools is genetic mapping. Genetic mapping - also called linkage mapping - can offer firm evidence that a disease transmitted from parent to child is linked to one or more genes. Mapping also provides clues about which chromosome contains the gene and precisely where the gene lies on that chromosome. Genetic maps have been used successfully to find the gene responsible for relatively rare, single-gene inherited disorders such as cystic fibrosis and Duchenne muscular dystrophy. Genetic maps are also useful in guiding scientists to the many genes that are believed to play a role in the development of more common disorders such as asthma, heart disease, diabetes, cancer, and psychiatric conditions.\"\n",
    "\n",
    "\n",
    "- [Pubmed articles](https://www.ncbi.nlm.nih.gov/books/NBK3827/#pubmedhelp.PubMed_Quick_Start): \"PubMed comprises over 29 million citations for biomedical literature from MEDLINE, life science journals, and online books. PubMed citations and abstracts include the fields of biomedicine and health, covering portions of the life sciences, behavioral sciences, chemical sciences, and bioengineering. PubMed also provides access to additional relevant web sites and links to the other NCBI molecular biology resources. PubMed is a free resource that is developed and maintained by the National Center for Biotechnology Information (NCBI), at the U.S. National Library of Medicine (NLM), located at the National Institutes of Health (NIH).\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame the Problem\n",
    "\n",
    "**Next steps:**\n",
    "\n",
    "- Abstracting the problem\n",
    "- Research about state-of-art application/solutions\n",
    "- Define and implement a simple application\n",
    "- Discuss better approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstracting the problem\n",
    "\n",
    "First of all, based on the challenge, it’s a Question Answering (QA) problem which inclus many parts of Natural Language Processing field. \n",
    "\n",
    "Nowadays we have pretty good search engines which make a hard job of rank the best papers based on our queris/question and that makes our lifes easier but is not enough. \n",
    "Lot’s of paper are produces by day and it’s impossible to follow all researches and dicoveries. Based on that a A.I. solution to comprehend these papers (or general text) using a specific and given context is being study and some important progress were achieved. This field is recognized for havaing a great potential and  biggest challenge of this field is develop a Open-Domain Question Answering solution that enables users to access the knowledge resources in a natural way and to get back a relevant and proper response in concise words. The major landmark of Open-Domain QA was the system developed by IBM Research to beat two champions at the game *Jeopardy!*. (For more information: [This is Watson - David A. Ferrucci, IBM Research Division](https://www.ibm.com/developerworks/community/files/app#/file/39ade3ad-8991-465a-826e-bfd39cd1e541))\n",
    "\n",
    "\n",
    "The next quotes demonstrate the importance of this field. \n",
    "\n",
    "\"Though automatic question answering will definitely be a significant advance in the state-of-art information\n",
    "retrieval technology in forthcoming years but still there are many challenging issues that are yet to be resolved. One of the challenging tasks for existing QA systems is to understand the natural language questions correctly and deduce the precise meaning to retrieve exact responses. Improvement in mechanized understanding of questions faces issues like question classification, formulation of right queries, ambiguity resolution, semantic symmetry detection, identification of temporal relationship in complex questions. In the similar way identification of a perfect answer requires proper validation mechanism.\" From [Research and Reviews in Question Answering System](https://www.sciencedirect.com/science/article/pii/S2212017313005409)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Overview of Question Answering\n",
    "\n",
    "[Research and reviews in question answering system](https://pdf.sciencedirectassets.com/282073/1-s2.0-S2212017313X00052/1-s2.0-S2212017313005409/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEAMaCXVzLWVhc3QtMSJHMEUCIQCYQuZVcR1FHzysAZIifXX3W08Nb3RtxZxvQM230hXqxgIgSkDtwodeaUtQDINwwPGCH2cMiSkqNOzt8SmAa%2F%2BX9m4q4wMI3P%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgwwNTkwMDM1NDY4NjUiDC43804kG2x4azORfCq3A4JsbjW%2B82Lu9rUQWKTxiTjc1NGz4sqLm01QQz4kfBsgExUhqFbEhxWOU1tay22IAydzDwJIUyYqhRo52KnVT5iOi4O87Alx5XVYtfkyxNGa2vFAKvvm7kjHI7OvCGQZib20x9UR9QxWQ7MaZTeuKXLxLiL6oTH8Oc%2BFEvkIae%2BysnvMQ6Do47wIZUTCLT2ZZPThKA6Ar4xrRguCBoj5wmvx2vmf2c1qtkmKMfFK4pOiZj3bHn8vJ1j%2Bv5vIzL0JPb6Dg4v8wEnvcpDK3BUXHezWZdXnPM2DVqnXjCa9flrhCQ4pVZvyynNvdaCx5srYSxq4f5hTYWQM9ruKLA7kY5Mv5G4Rw9geqABnnwbz0tER7pPxNZLe%2FM2bx49AdeC7Xi92BVPx6cPUSG0QMJ3xtByRPZa1Mlc3C%2BLrp%2FplGwTsEoq5FghkKdwlPMLSunxXI2FG4RACd2lP%2BGXDtf4ZkWsvPBzdADrIn57rEUlpX2FkUflOGgFI%2B%2FLwO%2BXiRGsg6yJsWIbZnJGCb5Xt8GocabHCFq1CzbxE%2BDgBJR8v9r07aKiUkB3KYODCx6KcebPHLW7P012CX0Yw2tSC5gU6tAFcu0p0WDfxAEzOnbDsDVtRevk5KjSPVRAw2v7w5iuK2GJe%2BmdDD4BmieK8nTETO%2BWJWFN4RXa5km6UMiS03ol6RynvClohfnmUjQWX7cqFytF02H%2Fw9aELvGdejmQkfvjRsknVRq1EaC00iKkzfEMV2gb2JEIHx3ICc7W6Up7BmTqAIqSjm3HYiD5EYERlN8Cx4py0ZrxQrXK9uh0YrWH8UTGBlY3bddqii1zQ8Ah1eYB1%2BV8%3D&AWSAccessKeyId=ASIAQ3PHCVTY65ZFRJ3M&Expires=1556132318&Signature=%2FV1EX1yBhflJBSTMaK0ah5aAgNU%3D&hash=d279400a992c15cb51256809feeebcbf24157f5106a54bbc9ca32af2a34a10b0&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S2212017313005409&tid=spdf-91b9ef03-c79a-418d-a91c-0ccbe50c6e8c&sid=88f86df424c5c741a188f3c0d8be46446ac3gxrqa&type=client)\n",
    "\n",
    "\n",
    "[A literature review on question answering techniques, paradigmsand systems.](https://reader.elsevier.com/reader/sd/pii/S131915781830082X?token=739A25D8B74882F560024B2C778361C686E83EAF8118DA1B64FE5FEF45D338CD36CED3F47351FF73F5BCDF108671DE74)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Usually a architecture of Question Answering systems is split into 3 modules:\n",
    "\n",
    "\n",
    "- **Question Processing:** It’s the first step and the goal is to analyse and classify the question using the question inputed. This process avoid ambiguities in the questions. \n",
    "\n",
    "- **Document Processing:** In this part, based on the undestanding form the question, the relevants documents are selected and the best parts of these docuemnts are extracted. \n",
    "\n",
    "- **Answer Processing:** based on the output of the previous step this module find out the answer for the question. It’s the most difficult part of the QA system.\n",
    "\n",
    "\n",
    "\n",
    "Besides the main architecture,  there are differents paradigm for QA systems:\n",
    "\n",
    "- **Information Retrieval QA:** Usage of search engines to retrieve answers and then apply filters and ranking on the recovered passage. ([A literature review on question answering techniques, paradigmsand systems.](https://reader.elsevier.com/reader/sd/pii/S131915781830082X?token=739A25D8B74882F560024B2C778361C686E83EAF8118DA1B64FE5FEF45D338CD36CED3F47351FF73F5BCDF108671DE74))\n",
    "\n",
    "- **Natural Language Processing QA:** Usage of linguistic intuitions and machine learning methods to extract answers from retrieved snippet. ([A literature review on question answering techniques, paradigmsand systems.](https://reader.elsevier.com/reader/sd/pii/S131915781830082X?token=739A25D8B74882F560024B2C778361C686E83EAF8118DA1B64FE5FEF45D338CD36CED3F47351FF73F5BCDF108671DE74))\n",
    "\n",
    "- **Knowledge Base QA:** Find answers from structured data source (a knowledge base) instead of unstructured text. Standard database queries are used in replacement of word-based searches. ([A literature review on question answering techniques, paradigmsand systems.](https://reader.elsevier.com/reader/sd/pii/S131915781830082X?token=739A25D8B74882F560024B2C778361C686E83EAF8118DA1B64FE5FEF45D338CD36CED3F47351FF73F5BCDF108671DE74))\n",
    "\n",
    "- **Hybrid QA:** High performance QA systems make use of as many types of resources as possible, especially with the prevailing popularity of modern search engines and enriching community-contributed knowledge on the web. A hybrid approach is the combination of IR QA, NLP QA and KB QA. The main example of this paradigm is IBM Watson. ([A literature review on question answering techniques, paradigmsand systems.](https://reader.elsevier.com/reader/sd/pii/S131915781830082X?token=739A25D8B74882F560024B2C778361C686E83EAF8118DA1B64FE5FEF45D338CD36CED3F47351FF73F5BCDF108671DE74))\n",
    "\n",
    "\n",
    "So, it’s clear that QA systems combine lot’s of area in computer science and AI. Some of related topics are:\n",
    "\n",
    "- Information Retrieval (IR)\n",
    "- Natural Language Processing (NLP)\n",
    "- Knowledge Representation and Reasoning (KR&R)\n",
    "- Machine Learning (ML)\n",
    "- Search Engine\n",
    "- Machine Reading Comprehension (MRC)\n",
    "\n",
    "\n",
    "**What are being used?**\n",
    "\n",
    "In the last years, Natural Language Process paradigm achieved great developments using neural network to solve Question Answering problems. Recurrent Neural Networks (RNNs), based on Gate Recurrent Unit (GRU) and Long Short-Term Memory (LSTM) units, is being widely used to handle the longer texts required for QA. Improvements like attention mecanisms and memory networks are currently performing the state-of-art solution for Natural Language Processing based QA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Basic Concepts Resources\n",
    "\n",
    "**Briefly BIG picture + Image**\n",
    "\n",
    "** ADD TOPIC WITH THE MAIN CECEPTS**\n",
    "\n",
    "- LMST\n",
    "- GRU\n",
    "- MEMM + article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM AND GRU - https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "\n",
    "https://skymind.ai/wiki/lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a simple solution\n",
    "\n",
    "\n",
    "The solution that I can propouse is to replicate the base line models using some open source solution. I’m  going to show the results of QA systems aplied into famous dataset called [bAbI Task Data](https://research.fb.com/downloads/babi/).\n",
    "\n",
    "### About the Dataset bAbI\n",
    "\n",
    "\n",
    "It's a dataset prepared by Facebook and consists of 20 question answering tasks. There are 1000 training/test context-question-answer example for each task. These task are listed below but for further information access [TOWARDS AI-COMPLETE QUESTION ANSWERING: A SET OF PREREQUISITE TOY TASKS, Facebook AI Reaserach](https://arxiv.org/pdf/1502.05698.pdf)\n",
    "\n",
    "- Task 1: Single Supporting Fact  \n",
    "- Task 2: Two Supporting Facts \n",
    "- Task 3: Three Supporting Facts\n",
    "- Task 4: Two Argument Relation \n",
    "- Task 5: Three Argument Relation \n",
    "- Task 6: Yes/No Questions\n",
    "- Task 7: Counting\n",
    "- Task 8: Lists/Sets\n",
    "- Task 9: Simple Negation\n",
    "- Task 10: Indefinite Knowledge \n",
    "- Task 11: Basic Coreference \n",
    "- Task 12: Conjunction\n",
    "- Task 13: Compound Coreference\n",
    "- Task 14: Time Reasoning\n",
    "- Task 15: Basic Deduction\n",
    "- Task 16: Basic Induction\n",
    "- Task 17: Positional Reasoning\n",
    "- Task 18: Size Reasoning\n",
    "- Task 19: Path Finding\n",
    "- Task 20: Agent’s Motivations\n",
    "\n",
    "\n",
    "\n",
    "    NOTE: Each task aims to test a unique aspect of reasoning and is, therefore, geared towards testing a specific capability of QA learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurent Neural Net Solution - Keras Example\n",
    "\n",
    "**ABOUT THE SOLUTION**\n",
    "\n",
    "The code below is a replication from Keras ([babi_rnn](https://github.com/keras-team/keras/blob/master/examples/babi_rnn.py)). It’s possible to implement a simple solution only using Keras library which achieves similar results with those found by the LSMT baseline provided by [Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks](https://arxiv.org/pdf/1502.05698.pdf) given only few samples.\n",
    "\n",
    "\n",
    "**ABOUT MODEL APPLIED - RNN (BASIC)**\n",
    "\n",
    "Two RNN - recurrent.LSTM\n",
    "\n",
    "\n",
    "https://smerity.com/articles/2015/keras_qa.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Trains two recurrent neural networks based upon a story and a question.\n",
    "The resulting merged vector is then queried to answer a range of bAbI tasks.\n",
    "\n",
    "Task Number                  | FB LSTM Baseline | Keras QA\n",
    "---                          | ---              | ---\n",
    "QA1 - Single Supporting Fact | 50               | 52.1\n",
    "QA2 - Two Supporting Facts   | 20               | 37.0\n",
    "QA3 - Three Supporting Facts | 20               | 20.5\n",
    "QA4 - Two Arg. Relations     | 61               | 62.9\n",
    "QA5 - Three Arg. Relations   | 70               | 61.9\n",
    "QA6 - yes/No Questions       | 48               | 50.7\n",
    "QA7 - Counting               | 49               | 78.9\n",
    "QA8 - Lists/Sets             | 45               | 77.2\n",
    "QA9 - Simple Negation        | 64               | 64.0\n",
    "QA10 - Indefinite Knowledge  | 44               | 47.7\n",
    "QA11 - Basic Coreference     | 72               | 74.9\n",
    "QA12 - Conjunction           | 74               | 76.4\n",
    "QA13 - Compound Coreference  | 94               | 94.4\n",
    "QA14 - Time Reasoning        | 27               | 34.8\n",
    "QA15 - Basic Deduction       | 21               | 32.4\n",
    "QA16 - Basic Induction       | 23               | 50.6\n",
    "QA17 - Positional Reasoning  | 51               | 49.1\n",
    "QA18 - Size Reasoning        | 52               | 90.8\n",
    "QA19 - Path Finding          | 8                | 9.0\n",
    "QA20 - Agent's Motivations   | 91               | 90.7\n",
    "For the resources related to the bAbI project, refer to:\n",
    "https://research.facebook.com/researchers/1543934539189348\n",
    "### Notes\n",
    "- With default word, sentence, and query vector sizes, the GRU model achieves:\n",
    "  - 52.1% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n",
    "  - 37.0% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU)\n",
    "In comparison, the Facebook paper achieves 50% and 20% for the LSTM baseline.\n",
    "- The task does not traditionally parse the question separately. This likely\n",
    "improves accuracy and is a good example of merging two RNNs.\n",
    "- The word vector embeddings are not shared between the story and question RNNs.\n",
    "- See how the accuracy changes given 10,000 training samples (en-10k) instead\n",
    "of only 1000. 1000 was used in order to be comparable to the original paper.\n",
    "- Experiment with GRU, LSTM, and JZS1-3 as they give subtly different results.\n",
    "- The length and noise (i.e. 'useless' story components) impact the ability of\n",
    "LSTMs / GRUs to provide the correct answer. Given only the supporting facts,\n",
    "these RNNs can achieve 100% accuracy on many tasks. Memory networks and neural\n",
    "networks that use attentional processes can efficiently search through this\n",
    "noise to find the relevant statements, improving performance substantially.\n",
    "This becomes especially obvious on QA2 and QA3, both far longer than QA1.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from functools import reduce\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true,\n",
    "    only the sentences that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file, retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data\n",
    "            if not max_length or len(flatten(story)) < max_length]\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    xs = []\n",
    "    xqs = []\n",
    "    ys = []\n",
    "    for story, query, answer in data:\n",
    "        x = [word_idx[w] for w in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        # let's not forget that index 0 is reserved\n",
    "        y = np.zeros(len(word_idx) + 1)\n",
    "        y[word_idx[answer]] = 1\n",
    "        xs.append(x)\n",
    "        xqs.append(xq)\n",
    "        ys.append(y)\n",
    "    return (pad_sequences(xs, maxlen=story_maxlen),\n",
    "            pad_sequences(xqs, maxlen=query_maxlen), np.array(ys))\n",
    "\n",
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "SENT_HIDDEN_SIZE = 100\n",
    "QUERY_HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,\n",
    "                                                           EMBED_HIDDEN_SIZE,\n",
    "                                                           SENT_HIDDEN_SIZE,\n",
    "                                                           QUERY_HIDDEN_SIZE))\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz',\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n",
    "          '.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "\n",
    "# Default QA1 with 1000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'\n",
    "# QA1 with 10,000 samples\n",
    "#challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
    "# QA2 with 1000 samples\n",
    "#challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n",
    "# QA2 with 10,000 samples\n",
    "challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n",
    "with tarfile.open(path) as tar:\n",
    "    train = get_stories(tar.extractfile(challenge.format('train')))\n",
    "    test = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "vocab = set()\n",
    "for story, q, answer in train + test:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train + test)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train + test)))\n",
    "\n",
    "x, xq, y = vectorize_stories(train, word_idx, story_maxlen, query_maxlen)\n",
    "tx, txq, ty = vectorize_stories(test, word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "print('vocab = {}'.format(vocab))\n",
    "print('x.shape = {}'.format(x.shape))\n",
    "print('xq.shape = {}'.format(xq.shape))\n",
    "print('y.shape = {}'.format(y.shape))\n",
    "print('story_maxlen, query_maxlen = {}, {}'.format(story_maxlen, query_maxlen))\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "sentence = layers.Input(shape=(story_maxlen,), dtype='int32')\n",
    "encoded_sentence = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(sentence)\n",
    "encoded_sentence = RNN(SENT_HIDDEN_SIZE)(encoded_sentence)\n",
    "\n",
    "question = layers.Input(shape=(query_maxlen,), dtype='int32')\n",
    "encoded_question = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\n",
    "encoded_question = RNN(QUERY_HIDDEN_SIZE)(encoded_question)\n",
    "\n",
    "merged = layers.concatenate([encoded_sentence, encoded_question])\n",
    "preds = layers.Dense(vocab_size, activation='softmax')(merged)\n",
    "\n",
    "model = Model([sentence, question], preds)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training')\n",
    "model.fit([x, xq], y,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.05)\n",
    "\n",
    "print('Evaluation')\n",
    "loss, acc = model.evaluate([tx, txq], ty,\n",
    "                           batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x138afec18>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'football',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'went',\n",
       "  'to',\n",
       "  'the',\n",
       "  'kitchen',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'kitchen',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'garden',\n",
       "  '.'],\n",
       " ['Where', 'is', 'the', 'football', '?'],\n",
       " 'garden')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Memory Network Solution - Keras Example \n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/babi_memnn.py\n",
    "\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1503.08895.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Network Solution - Keras Example\n",
    "\n",
    "**ABOUT THE SOLUTION**\n",
    "\n",
    "The code below is a replication from Keras ([babi_memnn](https://github.com/keras-team/keras/blob/master/examples/babi_memnn.py)). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It’s possible to implement a simple solution only using Keras library which achieves similar results with those found by the LSMT baseline provided by [Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks](https://arxiv.org/pdf/1502.05698.pdf) given only few samples.\n",
    "\n",
    "\n",
    "**ABOUT MODEL APPLIED - MemNN (BASIC)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting stories for the challenge: single_supporting_fact_10k\n",
      "-\n",
      "Vocab size: 22 unique words\n",
      "Story max length: 68 words\n",
      "Query max length: 4 words\n",
      "Number of training stories: 10000\n",
      "Number of test stories: 1000\n",
      "-\n",
      "Here's what a \"story\" tuple looks like (input, query, answer):\n",
      "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'John', 'went', 'to', 'the', 'hallway', '.'], ['Where', 'is', 'Mary', '?'], 'bathroom')\n",
      "-\n",
      "Vectorizing the word sequences...\n",
      "-\n",
      "inputs: integer tensor of shape (samples, max_length)\n",
      "inputs_train shape: (10000, 68)\n",
      "inputs_test shape: (1000, 68)\n",
      "-\n",
      "queries: integer tensor of shape (samples, max_length)\n",
      "queries_train shape: (10000, 4)\n",
      "queries_test shape: (1000, 4)\n",
      "-\n",
      "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
      "answers_train shape: (10000,)\n",
      "answers_test shape: (1000,)\n",
      "-\n",
      "Compiling...\n",
      "WARNING:tensorflow:From /Users/saito/anaconda3/envs/deep-learning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/saito/anaconda3/envs/deep-learning/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 3s 319us/step - loss: 1.9515 - acc: 0.1626 - val_loss: 1.7728 - val_acc: 0.1960\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 1.7187 - acc: 0.2416 - val_loss: 1.6444 - val_acc: 0.2940\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 1.6153 - acc: 0.3109 - val_loss: 1.5606 - val_acc: 0.3570\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 2s 208us/step - loss: 1.5347 - acc: 0.3696 - val_loss: 1.5607 - val_acc: 0.3670\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 1.5080 - acc: 0.3816 - val_loss: 1.5110 - val_acc: 0.3860\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 2s 196us/step - loss: 1.4975 - acc: 0.3893 - val_loss: 1.4904 - val_acc: 0.4150\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 2s 194us/step - loss: 1.4715 - acc: 0.4108 - val_loss: 1.4267 - val_acc: 0.4490\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 2s 189us/step - loss: 1.4398 - acc: 0.4395 - val_loss: 1.3953 - val_acc: 0.4630\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 2s 196us/step - loss: 1.4062 - acc: 0.4457 - val_loss: 1.3516 - val_acc: 0.4850\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 2s 200us/step - loss: 1.3909 - acc: 0.4598 - val_loss: 1.3521 - val_acc: 0.4940\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 2s 212us/step - loss: 1.3749 - acc: 0.4679 - val_loss: 1.3305 - val_acc: 0.4880\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 2s 205us/step - loss: 1.3562 - acc: 0.4767 - val_loss: 1.3103 - val_acc: 0.5060\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 1.3357 - acc: 0.4847 - val_loss: 1.3004 - val_acc: 0.5020\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 1.3219 - acc: 0.4926 - val_loss: 1.2851 - val_acc: 0.5170\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 2s 200us/step - loss: 1.3088 - acc: 0.5040 - val_loss: 1.2664 - val_acc: 0.5040\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 1.2807 - acc: 0.5083 - val_loss: 1.2327 - val_acc: 0.5260\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 1.2522 - acc: 0.5165 - val_loss: 1.2231 - val_acc: 0.5200\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 1.2366 - acc: 0.5131 - val_loss: 1.2375 - val_acc: 0.5050\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 1.2224 - acc: 0.5144 - val_loss: 1.2069 - val_acc: 0.5220\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 1.2097 - acc: 0.5171 - val_loss: 1.2052 - val_acc: 0.5210\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 1.2050 - acc: 0.5174 - val_loss: 1.2005 - val_acc: 0.4990\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 1.2017 - acc: 0.5147 - val_loss: 1.1837 - val_acc: 0.5080\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 1.1846 - acc: 0.5185 - val_loss: 1.1964 - val_acc: 0.5150\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 2s 207us/step - loss: 1.1788 - acc: 0.5185 - val_loss: 1.1843 - val_acc: 0.5060\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 2s 213us/step - loss: 1.1776 - acc: 0.5230 - val_loss: 1.1829 - val_acc: 0.5020\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 2s 213us/step - loss: 1.1698 - acc: 0.5207 - val_loss: 1.1608 - val_acc: 0.5200\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 1.1609 - acc: 0.5207 - val_loss: 1.1730 - val_acc: 0.5200\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 1.1519 - acc: 0.5302 - val_loss: 1.1692 - val_acc: 0.5080\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 1.1612 - acc: 0.5238 - val_loss: 1.1686 - val_acc: 0.5210\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 2s 208us/step - loss: 1.1586 - acc: 0.5226 - val_loss: 1.1615 - val_acc: 0.5200\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 2s 205us/step - loss: 1.1450 - acc: 0.5254 - val_loss: 1.1659 - val_acc: 0.5150\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 2s 216us/step - loss: 1.1467 - acc: 0.5308 - val_loss: 1.1683 - val_acc: 0.5200\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 1.1320 - acc: 0.5318 - val_loss: 1.1425 - val_acc: 0.5260\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 2s 204us/step - loss: 1.1284 - acc: 0.5299 - val_loss: 1.1433 - val_acc: 0.5230\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 2s 207us/step - loss: 1.1249 - acc: 0.5286 - val_loss: 1.1463 - val_acc: 0.5230\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 2s 205us/step - loss: 1.1128 - acc: 0.5407 - val_loss: 1.1404 - val_acc: 0.5310\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 2s 212us/step - loss: 1.1067 - acc: 0.5450 - val_loss: 1.1683 - val_acc: 0.5130\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 2s 212us/step - loss: 1.1043 - acc: 0.5468 - val_loss: 1.1082 - val_acc: 0.5310\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 1.0768 - acc: 0.5604 - val_loss: 1.0690 - val_acc: 0.5660\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 2s 207us/step - loss: 1.0096 - acc: 0.5976 - val_loss: 0.9706 - val_acc: 0.6390\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 0.8854 - acc: 0.6720 - val_loss: 0.8268 - val_acc: 0.7080\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 2s 207us/step - loss: 0.7637 - acc: 0.7274 - val_loss: 0.7171 - val_acc: 0.7410\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 0.6796 - acc: 0.7591 - val_loss: 0.6760 - val_acc: 0.7340\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 0.6302 - acc: 0.7719 - val_loss: 0.6050 - val_acc: 0.7590\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 2s 203us/step - loss: 0.5804 - acc: 0.7864 - val_loss: 0.5651 - val_acc: 0.7720\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 2s 207us/step - loss: 0.5417 - acc: 0.7967 - val_loss: 0.5316 - val_acc: 0.7870\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 2s 213us/step - loss: 0.5092 - acc: 0.8041 - val_loss: 0.4886 - val_acc: 0.8020\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 2s 208us/step - loss: 0.4735 - acc: 0.8198 - val_loss: 0.4753 - val_acc: 0.8030\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 2s 205us/step - loss: 0.4420 - acc: 0.8360 - val_loss: 0.4352 - val_acc: 0.8410\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 2s 200us/step - loss: 0.4281 - acc: 0.8414 - val_loss: 0.4062 - val_acc: 0.8420\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 0.3986 - acc: 0.8503 - val_loss: 0.4190 - val_acc: 0.8320\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 2s 204us/step - loss: 0.3813 - acc: 0.8574 - val_loss: 0.3767 - val_acc: 0.8660\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 2s 208us/step - loss: 0.3700 - acc: 0.8606 - val_loss: 0.3840 - val_acc: 0.8450\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 2s 218us/step - loss: 0.3540 - acc: 0.8682 - val_loss: 0.3688 - val_acc: 0.8500\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 2s 230us/step - loss: 0.3453 - acc: 0.8692 - val_loss: 0.3549 - val_acc: 0.8630\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 2s 237us/step - loss: 0.3369 - acc: 0.8748 - val_loss: 0.3566 - val_acc: 0.8620\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 2s 238us/step - loss: 0.3209 - acc: 0.8798 - val_loss: 0.3321 - val_acc: 0.8760\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 2s 228us/step - loss: 0.3231 - acc: 0.8782 - val_loss: 0.3424 - val_acc: 0.8670\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 2s 215us/step - loss: 0.3041 - acc: 0.8875 - val_loss: 0.3668 - val_acc: 0.8570\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 2s 208us/step - loss: 0.3016 - acc: 0.8857 - val_loss: 0.3054 - val_acc: 0.8830\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 2s 204us/step - loss: 0.2880 - acc: 0.8925 - val_loss: 0.3293 - val_acc: 0.8780\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 0.2839 - acc: 0.8925 - val_loss: 0.3398 - val_acc: 0.8640\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 2s 198us/step - loss: 0.2655 - acc: 0.9003 - val_loss: 0.3164 - val_acc: 0.8750\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 2s 220us/step - loss: 0.2575 - acc: 0.9020 - val_loss: 0.2989 - val_acc: 0.8880\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 2s 216us/step - loss: 0.2534 - acc: 0.9059 - val_loss: 0.2998 - val_acc: 0.8910\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 2s 218us/step - loss: 0.2476 - acc: 0.9082 - val_loss: 0.2696 - val_acc: 0.9020\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 2s 220us/step - loss: 0.2352 - acc: 0.9117 - val_loss: 0.2670 - val_acc: 0.9050\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 2s 216us/step - loss: 0.2222 - acc: 0.9200 - val_loss: 0.2523 - val_acc: 0.9080\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 0.2162 - acc: 0.9240 - val_loss: 0.2474 - val_acc: 0.9120\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 2s 212us/step - loss: 0.2097 - acc: 0.9231 - val_loss: 0.2287 - val_acc: 0.9170\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 2s 207us/step - loss: 0.1992 - acc: 0.9260 - val_loss: 0.2588 - val_acc: 0.9070\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 2s 212us/step - loss: 0.1947 - acc: 0.9318 - val_loss: 0.2226 - val_acc: 0.9210\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 2s 218us/step - loss: 0.1864 - acc: 0.9334 - val_loss: 0.2406 - val_acc: 0.9210\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 2s 213us/step - loss: 0.1703 - acc: 0.9395 - val_loss: 0.2060 - val_acc: 0.9270\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 0.1704 - acc: 0.9389 - val_loss: 0.2481 - val_acc: 0.9110\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 2s 203us/step - loss: 0.1642 - acc: 0.9424 - val_loss: 0.1888 - val_acc: 0.9290\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 2s 198us/step - loss: 0.1592 - acc: 0.9446 - val_loss: 0.1932 - val_acc: 0.9310\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 0.1542 - acc: 0.9446 - val_loss: 0.2007 - val_acc: 0.9300\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 0.1482 - acc: 0.9494 - val_loss: 0.2005 - val_acc: 0.9340\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 0.1403 - acc: 0.9510 - val_loss: 0.1695 - val_acc: 0.9450\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 2s 202us/step - loss: 0.1378 - acc: 0.9499 - val_loss: 0.1799 - val_acc: 0.9340\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 2s 204us/step - loss: 0.1327 - acc: 0.9524 - val_loss: 0.1919 - val_acc: 0.9350\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 2s 210us/step - loss: 0.1345 - acc: 0.9545 - val_loss: 0.2334 - val_acc: 0.9280\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 0.1295 - acc: 0.9560 - val_loss: 0.1766 - val_acc: 0.9420\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 0.1284 - acc: 0.9563 - val_loss: 0.1715 - val_acc: 0.9470\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 2s 205us/step - loss: 0.1241 - acc: 0.9570 - val_loss: 0.1636 - val_acc: 0.9460\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 2s 200us/step - loss: 0.1192 - acc: 0.9582 - val_loss: 0.1664 - val_acc: 0.9460\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 0.1182 - acc: 0.9604 - val_loss: 0.1734 - val_acc: 0.9430\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 0.1158 - acc: 0.9609 - val_loss: 0.1608 - val_acc: 0.9510\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 0.1075 - acc: 0.9642 - val_loss: 0.1887 - val_acc: 0.9400\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 2s 213us/step - loss: 0.1072 - acc: 0.9659 - val_loss: 0.1577 - val_acc: 0.9470\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 2s 213us/step - loss: 0.1065 - acc: 0.9641 - val_loss: 0.1549 - val_acc: 0.9450\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 0.1006 - acc: 0.9673 - val_loss: 0.1469 - val_acc: 0.9500\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 0.0988 - acc: 0.9653 - val_loss: 0.1646 - val_acc: 0.9520\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 0.1017 - acc: 0.9662 - val_loss: 0.1440 - val_acc: 0.9550\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 0.0988 - acc: 0.9672 - val_loss: 0.1539 - val_acc: 0.9500\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 2s 204us/step - loss: 0.0974 - acc: 0.9674 - val_loss: 0.1542 - val_acc: 0.9480\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 2s 203us/step - loss: 0.0943 - acc: 0.9678 - val_loss: 0.1487 - val_acc: 0.9540\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 0.0882 - acc: 0.9700 - val_loss: 0.1416 - val_acc: 0.9510\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 2s 202us/step - loss: 0.0890 - acc: 0.9700 - val_loss: 0.1498 - val_acc: 0.9520\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 2s 204us/step - loss: 0.0863 - acc: 0.9692 - val_loss: 0.1506 - val_acc: 0.9540\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 2s 210us/step - loss: 0.0903 - acc: 0.9716 - val_loss: 0.1401 - val_acc: 0.9540\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 0.0845 - acc: 0.9715 - val_loss: 0.1470 - val_acc: 0.9540\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 2s 210us/step - loss: 0.0776 - acc: 0.9736 - val_loss: 0.1352 - val_acc: 0.9610\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 2s 208us/step - loss: 0.0831 - acc: 0.9732 - val_loss: 0.1800 - val_acc: 0.9490\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 214us/step - loss: 0.0782 - acc: 0.9729 - val_loss: 0.1340 - val_acc: 0.9580\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 2s 213us/step - loss: 0.0731 - acc: 0.9757 - val_loss: 0.1283 - val_acc: 0.9600\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 2s 210us/step - loss: 0.0800 - acc: 0.9726 - val_loss: 0.1306 - val_acc: 0.9570\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 2s 216us/step - loss: 0.0787 - acc: 0.9737 - val_loss: 0.1225 - val_acc: 0.9590\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 2s 221us/step - loss: 0.0668 - acc: 0.9772 - val_loss: 0.1681 - val_acc: 0.9500\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 2s 223us/step - loss: 0.0771 - acc: 0.9739 - val_loss: 0.1592 - val_acc: 0.9520\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 2s 219us/step - loss: 0.0748 - acc: 0.9744 - val_loss: 0.1341 - val_acc: 0.9570\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 2s 221us/step - loss: 0.0733 - acc: 0.9771 - val_loss: 0.1315 - val_acc: 0.9630\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 2s 212us/step - loss: 0.0749 - acc: 0.9732 - val_loss: 0.1240 - val_acc: 0.9610\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 0.0682 - acc: 0.9767 - val_loss: 0.1350 - val_acc: 0.9580\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 0.0675 - acc: 0.9774 - val_loss: 0.1367 - val_acc: 0.9560\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 0.0632 - acc: 0.9786 - val_loss: 0.1230 - val_acc: 0.9630\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 0.0670 - acc: 0.9776 - val_loss: 0.1427 - val_acc: 0.9590\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 2s 208us/step - loss: 0.0664 - acc: 0.9776 - val_loss: 0.1615 - val_acc: 0.9500\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 0.0646 - acc: 0.9792 - val_loss: 0.1254 - val_acc: 0.9610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c0ede10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Trains a memory network on the bAbI dataset.\n",
    "References:\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  [\"Towards AI-Complete Question Answering:\n",
    "  A Set of Prerequisite Toy Tasks\"](http://arxiv.org/abs/1502.05698)\n",
    "- Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  [\"End-To-End Memory Networks\"](http://arxiv.org/abs/1503.08895)\n",
    "Reaches 98.6% accuracy on task 'single_supporting_fact_10k' after 120 epochs.\n",
    "Time per epoch: 3s on CPU (core i7).\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from functools import reduce\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true, only the sentences\n",
    "    that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file,\n",
    "    retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data\n",
    "            if not max_length or len(flatten(story)) < max_length]\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories(data):\n",
    "    inputs, queries, answers = [], [], []\n",
    "    for story, query, answer in data:\n",
    "        inputs.append([word_idx[w] for w in story])\n",
    "        queries.append([word_idx[w] for w in query])\n",
    "        answers.append(word_idx[answer])\n",
    "    return (pad_sequences(inputs, maxlen=story_maxlen),\n",
    "            pad_sequences(queries, maxlen=query_maxlen),\n",
    "            np.array(answers))\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz',\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n",
    "          '.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "\n",
    "\n",
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_'\n",
    "                                  'single-supporting-fact_{}.txt',\n",
    "    # QA2 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_'\n",
    "                                'two-supporting-facts_{}.txt',\n",
    "}\n",
    "challenge_type = 'single_supporting_fact_10k'\n",
    "challenge = challenges[challenge_type]\n",
    "\n",
    "print('Extracting stories for the challenge:', challenge_type)\n",
    "with tarfile.open(path) as tar:\n",
    "    train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "    test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "vocab = set()\n",
    "for story, q, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "print('-')\n",
    "print('Vocab size:', vocab_size, 'unique words')\n",
    "print('Story max length:', story_maxlen, 'words')\n",
    "print('Query max length:', query_maxlen, 'words')\n",
    "print('Number of training stories:', len(train_stories))\n",
    "print('Number of test stories:', len(test_stories))\n",
    "print('-')\n",
    "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
    "print(train_stories[0])\n",
    "print('-')\n",
    "print('Vectorizing the word sequences...')\n",
    "\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories)\n",
    "\n",
    "print('-')\n",
    "print('inputs: integer tensor of shape (samples, max_length)')\n",
    "print('inputs_train shape:', inputs_train.shape)\n",
    "print('inputs_test shape:', inputs_test.shape)\n",
    "print('-')\n",
    "print('queries: integer tensor of shape (samples, max_length)')\n",
    "print('queries_train shape:', queries_train.shape)\n",
    "print('queries_test shape:', queries_test.shape)\n",
    "print('-')\n",
    "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
    "print('answers_train shape:', answers_train.shape)\n",
    "print('answers_test shape:', answers_test.shape)\n",
    "print('-')\n",
    "print('Compiling...')\n",
    "\n",
    "# placeholders\n",
    "input_sequence = Input((story_maxlen,))\n",
    "question = Input((query_maxlen,))\n",
    "\n",
    "# encoders\n",
    "# embed the input sequence into a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=query_maxlen))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=query_maxlen))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)\n",
    "\n",
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "# compute a 'match' between the first input vector sequence\n",
    "# and the question vector sequence\n",
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
    "\n",
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "\n",
    "# the original paper uses a matrix multiplication for this reduction step.\n",
    "# we choose to use a RNN instead.\n",
    "answer = LSTM(32)(answer)  # (samples, 32)\n",
    "\n",
    "# one regularization layer -- more would probably be needed.\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=120,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END (April 26)\n",
    "\n",
    "**Below that is just draft**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT STEP (April 27)\n",
    "\n",
    "- Select good Git repo\n",
    "- Explain each replicable repository\n",
    "- Select best advanced solution/projects/API\n",
    "- Try advanced solution or the plan to achieve them\n",
    "- White a conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub replicable repositories\n",
    "\n",
    "\n",
    "[keras-question-and-answering-web-api](https://github.com/chen0040/keras-question-and-answering-web-api)\n",
    "\n",
    "\n",
    "[End-To-End Memory Networks for Question Answering](https://github.com/vinhkhuc/MemN2N-babi-python)\n",
    "\n",
    "[ End-To-End Memory Networks with sklearn-like interface using Tensorflow](https://github.com/domluna/memn2n)\n",
    "+ https://github.com/priyank87/memn2n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Famous Challenges and Dataset\n",
    "\n",
    "\n",
    "### Best Open-Souce API \n",
    "\n",
    "https://blog.rapidapi.com/best-nlp-api/\n",
    "\n",
    "\n",
    "**IBM Watson Solution**\n",
    "\n",
    "[Create a Natural Language Question Answering system with IBM Watson ](https://fartashh.github.io/post/qa-system-watson/)\n",
    "\n",
    "**Microsoft**\n",
    "[deep-learning-machine-reading-comprehension](https://www.microsoft.com/en-us/research/project/deep-learning-machine-reading-comprehension/)\n",
    "\n",
    "**Google**\n",
    "[BERT - google research](https://github.com/google-research/bert)\n",
    "\n",
    "\n",
    "### Q&A projects\n",
    "\n",
    "great resources - [Question Answering Using Deep Learning - Several approaches](https://cs224d.stanford.edu/reports/StrohMathur.pdf)\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resouces for Advantage Solutions\n",
    "\n",
    "\n",
    "[NLP — Building a Question Answering model SQuad](https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54)\n",
    "\n",
    "[Facebook Github - Babi ask](https://github.com/facebook/bAbI-tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- white a conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "**RELATED PAPERS**\n",
    "\n",
    "- [Teach Machine to Comprehend Text and Answer Question with Tensorflow ](https://hanxiao.github.io/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/)\n",
    "- [Dual Ask-Answer Network for Machine Reading Comprehension](https://arxiv.org/pdf/1809.01997.pdf)\n",
    "\n",
    "\n",
    "- [NLP — Building a Question Answering model ](https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54)\n",
    "- [Github - cs224n-Squad-Project](https://github.com/priya-dwivedi/cs224n-Squad-Project)\n",
    "\n",
    "\n",
    "- [Question Answering - State of art solutions](https://paperswithcode.com/task/question-answering)\n",
    "- [Large-scale Simple Question Answering with Memory Networks](https://paperswithcode.com/paper/large-scale-simple-question-answering-with)\n",
    "\n",
    "\n",
    "-[Simple intent recognition and question answering with DeepPavlov](https://medium.com/deeppavlov/simple-intent-recognition-and-question-answering-with-deeppavlov-c54ccf5339a9)\n",
    "- [Open-domain question answering with DeepPavlov](https://medium.com/deeppavlov/open-domain-question-answering-with-deeppavlov-c665d2ee4d65)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[question-answering-with-tensorflow](https://www.oreilly.com/ideas/question-answering-with-tensorflow)\n",
    "\n",
    "[Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflo](https://hanxiao.github.io/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/)\n",
    "\n",
    "\n",
    "\n",
    "- [NLP — Building a Question Answering model ](https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54)\n",
    "- [Github - cs224n-Squad-Project](https://github.com/priya-dwivedi/cs224n-Squad-Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Question Answering Using Deep Learning](https://cs224d.stanford.edu/reports/StrohMathur.pdf)\n",
    "\n",
    "[TOWARDS AI-COMPLETE QUESTION ANSWERING: A SET OF PREREQUISITE TOY TASKS](https://arxiv.org/pdf/1502.05698.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the final solution\n",
    "\n",
    "https://smerity.com/articles/2015/keras_qa.html\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/babi_rnn.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DEMO\n",
    "https://github.com/priyank87/memn2n\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation using Keras and Babi dataset\n",
    "\n",
    "\n",
    "## Implementation keras 1 (rnn) - DONE\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/babi_rnn.py\n",
    "\n",
    "## Implemntation Keras 2 (memm)\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/babi_memnn.py\n",
    "\n",
    "# Implementation using Python (End-ENd-Memory) + Demo\n",
    "https://github.com/vinhkhuc/MemN2N-babi-python\n",
    "\n",
    "\n",
    "# Implementation using seq2seq and memory network model in Keras + Demo\n",
    "https://github.com/vinhkhuc/MemN2N-babi-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
