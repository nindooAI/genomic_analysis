{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Today the biomedical after doing the genetic mapping need to manually search the referencing of the\n",
    "report on thousands of Pubmed articles.\n",
    "What takes a lot of biomedical time and makes it impossible him to impact other lives through his work.\n",
    "\n",
    "# Challenge \n",
    "\n",
    "- How would you help the biomedical with an AI that understands the context of scientific papers and make recommendations from the biomedical question?\n",
    "- What is the best approach / model for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undestanding the context (basic search)\n",
    "\n",
    "- [Biomedical](https://www.guiadacarreira.com.br/salarios/quanto-ganha-um-biomedico/): research, identifies and classifies microorganisms that cause diseases and develops or improves medicines and vaccines to combat and prevent these diseases.\n",
    "\n",
    "\n",
    "- [Genetic Mapping](https://www.genome.gov/10000715/genetic-mapping-fact-sheet/): \"Among the main goals of the Human Genome Project (HGP) was to develop new, better and cheaper tools to identify new genes and to understand their function. One of these tools is genetic mapping. Genetic mapping - also called linkage mapping - can offer firm evidence that a disease transmitted from parent to child is linked to one or more genes. Mapping also provides clues about which chromosome contains the gene and precisely where the gene lies on that chromosome. Genetic maps have been used successfully to find the gene responsible for relatively rare, single-gene inherited disorders such as cystic fibrosis and Duchenne muscular dystrophy. Genetic maps are also useful in guiding scientists to the many genes that are believed to play a role in the development of more common disorders such as asthma, heart disease, diabetes, cancer, and psychiatric conditions.\"\n",
    "\n",
    "\n",
    "- [Pubmed articles](https://www.ncbi.nlm.nih.gov/books/NBK3827/#pubmedhelp.PubMed_Quick_Start): \"PubMed comprises over 29 million citations for biomedical literature from MEDLINE, life science journals, and online books. PubMed citations and abstracts include the fields of biomedicine and health, covering portions of the life sciences, behavioral sciences, chemical sciences, and bioengineering. PubMed also provides access to additional relevant web sites and links to the other NCBI molecular biology resources. PubMed is a free resource that is developed and maintained by the National Center for Biotechnology Information (NCBI), at the U.S. National Library of Medicine (NLM), located at the National Institutes of Health (NIH).\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this search is to find out what is a good approach of this problem. So, I need to define a solution where the AI undestands the context of thousands of articles and recommend the best articles according with the queries from the biomedicals.\n",
    "\n",
    "**Next steps:**\n",
    "\n",
    "- Undestand the dataset and solfwares\n",
    "- Find out similar solutions\n",
    "- Define the best approach\n",
    "- Try to implement a simple solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Related articles \n",
    "\n",
    "- [How to Interpret PubMed Queries and Why It Matters](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5815840/)\n",
    "\n",
    "- [Evaluating Relevance Ranking Strategies for MEDLINE Retrieval](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2605593/)\n",
    "\n",
    "- [Evaluation of text-mining systems for biology: overview of the Second BioCreative community challenge.](https://www.ncbi.nlm.nih.gov/pubmed/18834487)\n",
    "\n",
    "- [Stop Words - NLP](https://medium.com/@makcedward/nlp-pipeline-stop-words-part-5-d6770df8a936)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A optional solution\n",
    "\n",
    "- [Biomedical natural language processing - Tools and resources](http://bio.nlplab.org/)\n",
    "\n",
    "- [Improving accuracy for identifying related PubMed queries by an integrated approach](https://core.ac.uk/download/pdf/82481638.pdf)\n",
    "\n",
    "- [Finding Query Suggestions for PubMed](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2815412/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval in PubMed\n",
    "\n",
    "\"The PubMed™ search engine uses the co-occurrence search strategy, with a considerable amount of query expansion called automatic term mapping. The automatic term mapping feature uses additional resources to translate and expand the query.\n",
    "\n",
    "The most significant additional resource used is the MeSH™ database, a controlled vocabulary of biomedical terms used for indexing journal articles in MEDLINE™, a collection of biomedical abstracts at NLM. For example, a PubMed™ search on the term cancer is automatically expanded to include the MeSH™ term for cancer, neoplasm. For a multiword search phrase, PubMed™ attempts to recognize the whole search phrase as a concept in MeSH™, as in the phrase ear infection. The search is then expanded to include the medical term for ear infection, otitis.\n",
    "\n",
    "If a multiword search phrase is not recognized as a MeSH™ concept, PubMed™ breaks apart the phrase and repeats the automatic term mapping process until a match is found. For example, the phrase *common cold vitamin C* is expanded to the following search:\n",
    "\n",
    "common cold AND (vitamin C OR ascorbic acid)\n",
    "\n",
    "If no subset of contiguous words is recognized as a concept in the MeSH™ database, then a regular co-occurrence search takes place in which the search is translated to a search of query words combined by the Boolean operator AND.\n",
    "\n",
    "PubMed™ handles a query enclosed in double quotes as a phrase. In that case, automatic term mapping is bypassed, and the phrase is searched in another database, the list of indexed phrases. If the query phrase is found in the list of indexed phrases, then PubMed™ retrieves the set of records that contain the query phrase; otherwise PubMed™ treats the search phrase as if it was entered without quotes. Handling a query as a phrase is very important; however, it is currently limited to the list of indexed phrases in PubMed™.\" [Appendix - How to Interpret PubMed Queries and Why It Matters](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5815840/#APP1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undestanding the dataset and solfwares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PubMed Phases  Dataset\n",
    "\n",
    "### Paper - [PubMed Phrases, an open set of coherent phrases for searching biomedical literature](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5996850/)\n",
    "\n",
    "**Abstract:** \"In biomedicine, key concepts are often expressed by multiple words (e.g., ‘zinc finger protein’). Previous work has shown treating a sequence of words as a meaningful unit, where applicable, is not only important for human understanding but also beneficial for automatic information seeking. Here we present a collection of PubMed® Phrases that are beneficial for information retrieval and human comprehension. We define these phrases as coherent chunks that are logically connected. To collect the phrase set, we apply the hypergeometric test to detect segments of consecutive terms that are likely to appear together in PubMed. These text segments are then filtered using the BM25 ranking function to ensure that they are beneficial from an information retrieval perspective. Thus, we obtain a set of 705,915 PubMed Phrases. We evaluate the quality of the set by investigating PubMed user click data and manually annotating a sample of 500 randomly selected noun phrases. We also analyze and discuss the usage of these PubMed Phrases in literature search.\"\n",
    "\n",
    "\n",
    "So, the PubMed Phrases dataset is a collection of *phrases* which are usuful (beneficial) from an infomation retrieval perspective. It's not a model.\n",
    "\n",
    "* Since 2017, the PubMed Phrase set has been used for indexing documents in PubMed’s new relevance search (https://www.nlm.nih.gov/pubs/techbull/jf17/jf17_pm_best_match_sort.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilistic Relevance Framework - BM25**\n",
    "\n",
    " - [Probabilistic Relevance Framework: BM25 and beyond](http://www.staff.city.ac.uk/~sb317/papers/foundations_bm25_review.pdf)\n",
    "\n",
    "- [Wikepedia - Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOrd2Vector Dataset \n",
    "\n",
    "**Basic concepts about word2vector**\n",
    "- [Basic word2vector](https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281)\n",
    "- [Google - word2vec](https://code.google.com/archive/p/word2vec/)\n",
    "- [How to Train Good Word Embeddings for Biomedical NLP](https://www.aclweb.org/anthology/W16-2922)\n",
    "\n",
    "### Paper - [Bridging the gap: Incorporating a semantic similarity measure for effectively mapping PubMed queries to documents.](https://www.ncbi.nlm.nih.gov/pubmed/28986328)\n",
    "\n",
    "\n",
    "\n",
    "**Abstract:** \"The main approach of traditional information retrieval (IR) is to examine how many words from a query appear in a document. A drawback of this approach, however, is that it may fail to detect relevant documents where no or only few words from a query are found. The semantic analysis methods such as LSA (latent semantic analysis) and LDA (latent Dirichlet allocation) have been proposed to address the issue, but their performance is not superior compared to common IR approaches. Here we present a query-document similarity measure motivated by the Word Mover’s Distance. Unlike other similarity measures, the proposed method relies on neural word embeddings to compute the distance between words. This process helps identify related words when no direct matches are found between a query and a document. Our method is efficient and straightforward to implement. The experimental results on TREC Genomics data show that our approach outperforms the BM25 ranking function by an average of 12% in mean average precision. Furthermore, for a real-world dataset collected from the PubMed® search logs, we combine the semantic measure with BM25 using a learning to rank method, which leads to improved ranking scores by up to 25%. This experiment demonstrates that the proposed approach and BM25 nicely complement each other and together produce superior performance.\"\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Tradional *information retrieval* (IR) approach uses the term vectors representation of queries and documents and determine the similarity as a dot product or cosine similarity but the problem is that queries and documents should share exactly the SAME words. An alternative is to use Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) because these methods don’t requires SAME words between queries and documents. On the other hand, this semantic methods don’t results in better ranking when compared with classic ranking methods like BM25.\n",
    "So, a query-document similarity measure using a neural word embedding approach based on Word Mover's Distance was presented in this article. The method was validated on a simple dataset and after was tested on a PubMed dataset combining this semantic and BM25 approaches. So, *Learning to Rank* merged both approaches resulting into a better word embabedding model. The output of the trained model is avaible on https://www.ncbi.nlm.nih.gov/IRET/DATASET.\n",
    "\n",
    "\n",
    "\n",
    "- [Learning to Rank](http://didawikinf.di.unipi.it/lib/exe/fetch.php/magistraleinformatica/ir/ir13/1_-_learning_to_rank.pdf)\n",
    "\n",
    "\n",
    "**SIMILAR APPLICATIONS**\n",
    "\n",
    "https://github.com/jakerochlinmarcus/biomedical-word-embeddings\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim-data/issues/28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meshable dataset\n",
    "\n",
    "- [Medical Subject Heading (MeSH)](https://www.nlm.nih.gov/mesh/meshhome.html)\n",
    "- [Meshable: searching PubMed abstracts by utilizing MeSH and MeSH-derived topical terms](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5039918/)\n",
    "\n",
    "\"Medical Subject Headings (MeSH®) is a controlled vocabulary for indexing and searching biomedical literature. MeSH terms and subheadings are organized in a hierarchical structure and are used to indicate the topics of an article. Biologists can use either MeSH terms as queries or the MeSH interface provided in PubMed® for searching PubMed abstracts. However, these are rarely used, and there is no convenient way to link standardized MeSH terms to user queries. Here, we introduce a web interface which allows users to enter queries to find MeSH terms closely related to the queries. **Our method relies on co-occurrence of text words and MeSH terms to find keywords that are related to each MeSH term.** A query is then matched with the keywords for MeSH terms, and candidate MeSH terms are ranked based on their relatedness to the query. The experimental results show that our method achieves the best performance among several term extraction approaches in terms of topic coherence. Moreover, the interface can be effectively used to find full names of abbreviations and to disambiguate user queries.\"\n",
    "\n",
    "More frequently the MeSH resource is used indirectly by expanding a text query with the related MeSH term.\n",
    "For example, the query *ear infection* is automatically expanded to include the MeSH term otitis[MeSH]. However, such expansions are limited to terms listed as synonyms or variants for a given MeSH term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCBITextLib \n",
    "\n",
    "- [Solfware Library](https://github.com/ncbi-nlp/NCBITextLib)\n",
    "\n",
    "\"NCBITextLib is a simple but effective software library that allows one to build and access an infrastructure for large-scale text mining tasks. This library only provides basic C++ classes for building various text mining tools. Since the library provides a simple to use interface for connecting an internal text data structure to other high-level applications, it is straightforward to build ML software upon NCBITextLib. Currently, we provide three machine learning classes (naive Bayes, support vector machine and theme analysis algorithms) and example codes that use NCBITextLib\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.I. solutions to I.R. problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count x Predict\n",
    "\n",
    "### Paper - [Don’t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors](https://www.aclweb.org/anthology/P14-1023)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Match: New relevance search for PubMed\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6112631/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [A Machine Learning Approach for Improved BM25 Retrieval](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/LearningBM25MSRTechReport.pdf)\n",
    "\n",
    "- dkmskd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Information Retrieval in Biomedical Research: From Articles to Datasets\n",
    "](https://escholarship.org/uc/item/660390nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Biomedical natural language processing - Tools and resources](http://bio.nlplab.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [A tutorial on information retrieval: basic terms and concepts](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1459215/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [PubMed related articles: a probabilistic topic-based model for content similarity](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminar Conclusion and Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ate agora entendo que o problema em questão faz parte da area de Natural Language Processing (NLP) e mais especificamente um problema de Information Retrieval (IR). Inicialmente eu apenas busquei entender os dataset e softwares fornecidos. Consegui entender como foi gerado o dataset *PubMed Phrases* e como esse dataset gerou melhores resultados   \n",
    "\n",
    "\n",
    "arquivquais são os modelos classico que atuam nas search engines, principalmente a do PubMed, que é de onde vem meus datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
